{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b7f59fc",
   "metadata": {},
   "source": [
    "# Process Kantonsratsprotokolle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eefc59fe-95a2-4855-a991-6eb9887c14f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13039229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_seq_items = 500\n",
    "pandarallel.initialize(progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a746a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from staatsarchiv_utils import read_XML_files\n",
    "from staatsarchiv_utils import parse_XML_files\n",
    "from staatsarchiv_utils import fix_missing_dates\n",
    "from staatsarchiv_utils import fix_incomplete_dates\n",
    "from staatsarchiv_utils import parse_dates\n",
    "from staatsarchiv_utils import clean_identifiers\n",
    "from staatsarchiv_utils import generic_text_cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de128eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "DATA_INPUT_KRP = os.getenv(\"DATA_INPUT_KRP\")\n",
    "RAW_OUTPUT_KRP = os.getenv(\"RAW_OUTPUT_KRP\")\n",
    "PREP_OUTPUT_KRP = os.getenv(\"PREP_OUTPUT_KRP\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c53fa932-ae76-4509-b339-d8f7e45db481",
   "metadata": {},
   "source": [
    "**Prepare data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a4e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44,418 files found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44418/44418 [01:42<00:00, 435.46it/s]\n"
     ]
    }
   ],
   "source": [
    "file_paths = read_XML_files(DATA_INPUT_KRP)\n",
    "df = parse_XML_files(file_paths)\n",
    "df.to_parquet(RAW_OUTPUT_KRP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa40c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44,418 documents in data set.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44418 entries, 0 to 44417\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   path       44418 non-null  object\n",
      " 1   date_when  44321 non-null  object\n",
      " 2   date_from  97 non-null     object\n",
      " 3   date_to    97 non-null     object\n",
      " 4   date_text  44418 non-null  object\n",
      " 5   ident      44418 non-null  object\n",
      " 6   ref        44418 non-null  object\n",
      " 7   title      44418 non-null  object\n",
      " 8   text       44418 non-null  object\n",
      " 9   filename   44418 non-null  object\n",
      " 10  new_link   44418 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 874.6 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(RAW_OUTPUT_KRP)\n",
    "\n",
    "# Sanity check that we haven't imported duplicated data.\n",
    "assert df.duplicated().sum() == 0\n",
    "\n",
    "print(f\"{len(df):,.0f} documents in data set.\\n\")\n",
    "\n",
    "# TODO: Here the correct url of zszh has to be set\n",
    "link_prolog = \"https://www.zentraleserien.zh.ch/krp/\"\n",
    "df[\"new_link\"] = df.filename.apply(lambda x: link_prolog + x.replace(\".xml\", \"\"))\n",
    "assert df.new_link.nunique() == len(df)\n",
    "\n",
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fb6c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1803-04-18 00:00:00 1995-04-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Fix missing dates: Feature `date_when` is crucial. If this feature is missing, we agreed to fill in with the date from `date_from`.\n",
    "# Fix incomplete dates: More than 100 dates can't be parsed because the day is missing. We therefore add the first day of the time range as the day.\n",
    "# Clean identifiers: Several ident values contain line breaks and multiple spaces. We agredd to remove these programmatically.\n",
    "\n",
    "df = (\n",
    "    df.pipe(fix_missing_dates)\n",
    "    .pipe(fix_incomplete_dates)\n",
    "    .pipe(parse_dates)\n",
    "    .pipe(clean_identifiers)\n",
    ")\n",
    "\n",
    "# Sanity checks.\n",
    "assert df.date_when.isna().sum() == 0\n",
    "tmp = pd.to_datetime(df.date_when, errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "assert len(tmp[tmp.isna()].index) == 0\n",
    "assert df.ident.str.contains(\"\\n\").sum() == 0\n",
    "print(df.date_when.min(), df.date_when.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759f20e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44418 entries, 0 to 44417\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   identifier   44418 non-null  object        \n",
      " 1   date         44418 non-null  datetime64[ns]\n",
      " 2   year         44418 non-null  int32         \n",
      " 3   title        44418 non-null  object        \n",
      " 4   text         44418 non-null  object        \n",
      " 5   link         44418 non-null  object        \n",
      " 6   stazh_ident  44418 non-null  object        \n",
      " 7   ref          44418 non-null  object        \n",
      "dtypes: datetime64[ns](1), int32(1), object(6)\n",
      "memory usage: 843.6 MB\n"
     ]
    }
   ],
   "source": [
    "df[\"year\"] = df.date_when.dt.year\n",
    "df[\"identifier\"] = df.index.astype(int)\n",
    "df.identifier = [\"krp_\" + str(x) for x in df.identifier]\n",
    "df.rename(\n",
    "    {\"new_link\": \"link\"}, axis=1, inplace=True\n",
    ")  # TODO: Rename here (new_link : link)\n",
    "df.rename({\"date_when\": \"date\"}, axis=1, inplace=True)\n",
    "df.rename({\"ident\": \"stazh_ident\"}, axis=1, inplace=True)\n",
    "\n",
    "# Generic text cleaning.\n",
    "df.title = df.title.parallel_map(generic_text_cleaning)\n",
    "df.text = df.text.parallel_map(generic_text_cleaning)\n",
    "\n",
    "# Reduce to relevant columns and save to disk.\n",
    "cols = [\"identifier\", \"date\", \"year\", \"title\", \"text\", \"link\", \"stazh_ident\", \"ref\"]\n",
    "df = df[cols]\n",
    "df.to_parquet(PREP_OUTPUT_KRP)\n",
    "df.info(memory_usage=\"deep\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
